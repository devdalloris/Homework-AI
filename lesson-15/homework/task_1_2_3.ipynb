{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task 1: Bernoulli Naive Bayes on Binary Text Data\n",
    "\n",
    "* Task 1 Setup: SMS Spam Classification using Bernoulli Naive Bayes\n",
    "\n",
    "* Step 1: Load the dataset from this URL:\n",
    "* https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\n",
    "\n",
    "* Step 2: Convert the 'label' column into binary values: spam = 1, ham = 0\n",
    "\n",
    "* Step 3: Use CountVectorizer with binary=True to transform the text into binary features\n",
    "\n",
    "* Step 4: Split the dataset into training and test sets (e.g., 70/30 split)\n",
    "\n",
    "* Step 5: Initialize and train a BernoulliNB model\n",
    "\n",
    "* Step 6: Predict on the test set and evaluate using accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9749\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1448\n",
      "           1       0.97      0.84      0.90       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.97      0.92      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n",
      "Message: Congra wotulations! Youn a free lottery. Click here to claim your prize! → Prediction: Ham\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n",
    "\n",
    "df = pd.read_csv(base_url, sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['message'])  # Feature matrix\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Bernouli Naïve Bayes classifier\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict new messages\n",
    "def predict_message(msg):\n",
    "    # msg_clean = clean_text(msg)  # Preprocess message\n",
    "    msg_vectorized = vectorizer.transform([msg])  # Convert to TF-IDF vector\n",
    "    prediction = model.predict(msg_vectorized)[0]\n",
    "    return \"Spam\" if prediction == 1 else \"Ham\"\n",
    "\n",
    "# Test with a new message\n",
    "new_message = \"Congra wotulations! Youn a free lottery. Click here to claim your prize!\"\n",
    "print(f\"Message: {new_message} → Prediction: {predict_message(new_message)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Gaussian Naive Bayes on Real-Valued Data\n",
    "\n",
    "* Task 2 Setup: Iris Dataset with Gaussian Naive Bayes\n",
    "\n",
    "* Step 1: Load the Iris dataset using sklearn.datasets.load_iris()\n",
    "\n",
    "* Step 2: Split the data into training and test sets (e.g., 70/30 split)\n",
    "\n",
    "* Step 3: Initialize a GaussianNB model\n",
    "\n",
    "* Step 4: Train the model and evaluate performance using accuracy and classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Train a Gaussian Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Multinomial Naive Bayes on Word Frequencies\n",
    "\n",
    "* Task 3 Setup: SMS Spam Classification using Multinomial Naive Bayes\n",
    "\n",
    "* Step 1: Reuse the same SMS Spam dataset from Task 1\n",
    "\n",
    "* Step 2: Use CountVectorizer (without binary=True) to extract word frequency features\n",
    "\n",
    "* Step 3: Split the data into training and test sets\n",
    "\n",
    "* Step 4: Initialize and train a MultinomialNB model\n",
    "\n",
    "* Step 5: Evaluate the model with appropriate metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9850\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1448\n",
      "           1       0.93      0.96      0.95       224\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.96      0.97      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n",
      "Message: Congra wotulations! Youn a free lottery. Click here to claim your prize! → Prediction: Spam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n",
    "\n",
    "df = pd.read_csv(base_url, sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['message'])  # Feature matrix\n",
    "y = df['label']  # Target variable\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Bernouli Naïve Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict new messages\n",
    "def predict_message(msg):\n",
    "    # msg_clean = clean_text(msg)  # Preprocess message\n",
    "    msg_vectorized = vectorizer.transform([msg])  # Convert to TF-IDF vector\n",
    "    prediction = model.predict(msg_vectorized)[0]\n",
    "    return \"Spam\" if prediction == 1 else \"Ham\"\n",
    "\n",
    "# Test with a new message\n",
    "new_message = \"Congra wotulations! Youn a free lottery. Click here to claim your prize!\"\n",
    "print(f\"Message: {new_message} → Prediction: {predict_message(new_message)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
